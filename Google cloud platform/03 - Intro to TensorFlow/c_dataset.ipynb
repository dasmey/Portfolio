{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge Exercise\n",
    "\n",
    "Create a neural network that is capable of finding the volume of a cylinder given the radius of its base (r) and its height (h). Assume that the radius and height of the cylinder are both in the range 0.5 to 2.0. Unlike in the challenge exercise for b_estimator.ipynb, assume that your measurements of r, h and V are all rounded off to the nearest 0.1. Simulate the necessary training dataset. This time, you will need a lot more data to get a good predictor.\n",
    "\n",
    "Hint (highlight to see):\n",
    "<p style='color:white'>\n",
    "Create random values for r and h and compute V. Then, round off r, h and V (i.e., the volume is computed from the true value of r and h; it's only your measurement that is rounded off). Your dataset will consist of the round values of r, h and V. Do this for both the training and evaluation datasets.\n",
    "</p>\n",
    "\n",
    "Now modify the \"noise\" so that instead of just rounding off the value, there is up to a 10% error (uniformly distributed) in the measurement followed by rounding off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(np.random.uniform(0.5, 2, 1000000), columns = ['radius'])\n",
    "df_train['height'] = np.random.uniform(0.5, 2, 1000000)\n",
    "\n",
    "df_valid = pd.DataFrame(np.random.uniform(0.5, 2, 10000), columns = ['radius'])\n",
    "df_valid['height'] = np.random.uniform(0.5, 2, 10000)\n",
    "\n",
    "df_test = pd.DataFrame(np.random.uniform(0.5, 2, 10000), columns = ['radius'])\n",
    "df_test['height'] = np.random.uniform(0.5, 2, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for index, row in df_train.iterrows():\n",
    "  volume = math.pi * row['radius']**2 * row['height']\n",
    "  labels.append(volume)\n",
    "df_train['volume'] = labels\n",
    "\n",
    "labels.clear()\n",
    "for index, row in df_valid.iterrows():\n",
    "  volume = math.pi * row['radius']**2 * row['height']\n",
    "  labels.append(volume)\n",
    "df_valid['volume'] = labels\n",
    "\n",
    "labels.clear()\n",
    "for index, row in df_test.iterrows():\n",
    "  volume = math.pi * row['radius']**2 * row['height']\n",
    "  labels.append(volume)\n",
    "df_test['volume'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = round(df_train, 1)\n",
    "df_valid = round(df_valid, 1)\n",
    "df_test = round(df_test, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('df_train.csv', header = False)\n",
    "df_valid.to_csv('df_valid.csv', header = False)\n",
    "df_test.to_csv('df_test.csv', header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_COLUMNS = ['radius', 'height', 'volume', 'key']\n",
    "DEFAULTS = [[1.0], [1.0], [5.0], ['nokey']]\n",
    "\n",
    "def read_dataset(filename, mode, batch_size = 512) :\n",
    "  def decode_csv(row):\n",
    "    columns = tf.decode_csv(row, record_defaults = DEFAULTS)\n",
    "    features = dict(zip(CSV_COLUMNS, columns))\n",
    "    label = features.pop('volume')\n",
    "    return features, label\n",
    "  \n",
    "  filenames_dataset = tf.data.Dataset.list_files(filename)\n",
    "  textlines_dataset = filenames_dataset.flat_map(tf.data.TextLineDataset)\n",
    "  dataset = textlines_dataset.map(decode_csv)\n",
    "  \n",
    "  if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "    num_epochs = None\n",
    "    dataset = dataset.shuffle(buffer_size = 10 * batch_size)\n",
    "  else:\n",
    "    num_epochs = 1\n",
    "\n",
    "  dataset = dataset.repeat(num_epochs).batch(batch_size)\n",
    "  \n",
    "  return dataset\n",
    "\n",
    "def get_train_input_fn():\n",
    "  return read_dataset('./df_train.csv', mode = tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "def get_valid_input_fn():\n",
    "  return read_dataset('./df_valid.csv', mode = tf.estimator.ModeKeys.EVAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_COLUMNS = [\n",
    "  tf.feature_column.numeric_column('radius'),\n",
    "  tf.feature_column.numeric_column('height'),\n",
    "]\n",
    "\n",
    "def add_more_features(feats):\n",
    "  # nothing yet\n",
    "  return feats\n",
    "\n",
    "feature_cols = add_more_features(INPUT_COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_service': None, '_session_config': None, '_save_checkpoints_secs': 600, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f6c0e7e8c88>, '_evaluation_master': '', '_train_distribute': None, '_task_type': 'worker', '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_is_chief': True, '_global_id_in_cluster': 0, '_tf_random_seed': None, '_log_step_count_steps': 100, '_keep_checkpoint_every_n_hours': 10000, '_num_ps_replicas': 0, '_model_dir': 'df_trained', '_master': '', '_task_id': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into df_trained/model.ckpt.\n",
      "INFO:tensorflow:loss = 881.8299, step = 1\n",
      "INFO:tensorflow:global_step/sec: 45.3798\n",
      "INFO:tensorflow:loss = 209.32591, step = 101 (2.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 46.7169\n",
      "INFO:tensorflow:loss = 134.34381, step = 201 (2.138 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.1639\n",
      "INFO:tensorflow:loss = 104.03586, step = 301 (2.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.181\n",
      "INFO:tensorflow:loss = 95.76792, step = 401 (2.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.6059\n",
      "INFO:tensorflow:loss = 96.87262, step = 501 (2.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.7195\n",
      "INFO:tensorflow:loss = 98.238495, step = 601 (2.052 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.238\n",
      "INFO:tensorflow:loss = 97.58652, step = 701 (2.073 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.9961\n",
      "INFO:tensorflow:loss = 88.29881, step = 801 (2.084 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.3331\n",
      "INFO:tensorflow:loss = 95.67772, step = 901 (2.072 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into df_trained/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 90.12184.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNRegressor at 0x7f6c0e7e8be0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "OUTDIR = \"df_trained\"\n",
    "shutil.rmtree(OUTDIR, ignore_errors = True)\n",
    "model = tf.estimator.DNNRegressor(\n",
    "  hidden_units = [32, 8, 2],\n",
    "  feature_columns = feature_cols,\n",
    "  model_dir = OUTDIR)\n",
    "model.train(input_fn = get_train_input_fn, steps = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-11-14-12:29:32\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from df_trained/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-11-14-12:29:33\n",
      "INFO:tensorflow:Saving dict for global step 1000: average_loss = 0.19052127, global_step = 1000, loss = 95.260635\n",
      "RMSE on dataset = 0.43648743629455566\n"
     ]
    }
   ],
   "source": [
    "metrics = model.evaluate(input_fn = get_valid_input_fn, steps = None)\n",
    "print('RMSE on dataset = {}'.format(np.sqrt(metrics['average_loss'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now modify the \"noise\" so that instead of just rounding off the value, there is up to a 10% error (uniformly distributed) in the measurement followed by rounding off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We go back to the generator step and add some noise after the round off\n",
    "\n",
    "noise = np.random.uniform(-1, 1, 10000)\n",
    "\n",
    "df_train2['volume'] = round(df_train['volume'] + noise*0.1, 1) \n",
    "\n",
    "# check 2d code lab to see how it works\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2017 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
